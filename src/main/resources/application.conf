akka {
  log-config-on-start = false
  persistence {
    journal {
      plugin = "cassandra-journal"
    }
    snapshot-store {
      plugin = "cassandra-snapshot-store"
    }
  }
  actor {
    serializers {
      proto = "akka.remote.serialization.ProtobufSerializer"
    }
    serialization-bindings {
      "example.domain.ProtoDataPointAdded" = proto
    }
  }
}

cassandra {
  host = "127.0.0.1"
}

cassandra-journal {
  event-adapters {
    protobuf = "example.akka.ProtoBuffAdapter"
  }

  event-adapter-bindings {
    "example.domain.DataPointAdded" = protobuf
  }

  # FQCN of the cassandra journal plugin
  class = "akka.persistence.cassandra.journal.CassandraJournal"

  # Comma-separated list of contact points in the cluster
  contact-points = [${cassandra.host}]

  # Port of contact points in the cluster
  port = 9042

  # Name of the keyspace to be created/used by the journal
  keyspace = "akka_example"

  # Parameter indicating whether the journal keyspace should be auto created
  keyspace-autocreate = true

  # In case that schema creation failed you can define a number of retries before giving up.
  keyspace-autocreate-retries = 1

  # The number of retries when a write request returns a TimeoutException or an UnavailableException.
  write-retries = 3

  # Deletes are achieved using a metadata entry and then the actual messages are deleted asynchronously
  # Number of retries before giving up
  delete-retries = 3

  # Number of retries before giving up connecting to the cluster
  connect-retries = 3

  # Delay between connection retries
  connect-retry-delay = 5s

  # Name of the table to be created/used by the journal
  table = "messages"

  # Compaction strategy for the journal table
  table-compaction-strategy {
    class = "SizeTieredCompactionStrategy"
  }

  # Name of the table to be created/used for storing metadata
  metadata-table = "metadata"

  # Name of the table to be created/used for journal config
  config-table = "config"

  # replication strategy to use. SimpleStrategy or NetworkTopologyStrategy
  replication-strategy = "SimpleStrategy"

  # Replication factor to use when creating a keyspace. Is only used when replication-strategy is SimpleStrategy.
  replication-factor = 1

  # Replication factor list for data centers, e.g. ["dc1:3", "dc2:2"]. Is only used when replication-strategy is NetworkTopologyStrategy.
  data-center-replication-factors = []

  # Write consistency level
  write-consistency = "LOCAL_QUORUM"

  # Read consistency level
  read-consistency = "LOCAL_QUORUM"

  max-message-batch-size = 200

  # Target number of entries per partition (= columns per row).
  # Must not be changed after table creation (currently not checked).
  # This is "target" as AtomicWrites that span parition boundaries will result in bigger partitions to ensure atomicity.
  target-partition-size = 500000

  # Maximum size of result set
  max-result-size = 50001

  # Dispatcher for the plugin actor.
  plugin-dispatcher = "cassandra-journal.default-dispatcher"

  # Dispatcher for fetching and replaying messages
  replay-dispatcher = "akka.persistence.dispatchers.default-replay-dispatcher"

  # Default dispatcher for plugin actor.
  default-dispatcher {
    type = Dispatcher
    executor = "fork-join-executor"
    fork-join-executor {
      parallelism-min = 2
      parallelism-max = 8
    }
  }

  # The time to wait before cassandra will remove the thombstones created for deleted entries.
  # cfr. gc_grace_seconds table property documentation on http://www.datastax.com/documentation/cql/3.1/cql/cql_reference/tabProp.html
  gc-grace-seconds = 864000
}

cassandra-snapshot-store {

  # FQCN of the cassandra snapshot store plugin
  class = "akka.persistence.cassandra.snapshot.CassandraSnapshotStore"

  # Comma-separated list of contact points in the cluster
  contact-points = [${cassandra.host}]

  # Port of contact points in the cluster
  port = 9042

  # Name of the keyspace to be created/used by the snapshot store
  keyspace = "akka_example_snapshot"

  # Parameter indicating whether the snapshot keyspace should be auto created
  keyspace-autocreate = true

  # In case that schema creation failed you can define a number of retries before giving up.
  keyspace-autocreate-retries = 1

  # Number of retries before giving up connecting to the cluster
  connect-retries = 3

  # Delay between connection retries
  connect-retry-delay = 5s

  # Name of the table to be created/used by the snapshot store
  table = "snapshots"

  # Compaction strategy for the snapshot table
  table-compaction-strategy {
    class = "SizeTieredCompactionStrategy"
  }

  # Name of the table to be created/used for journal config
  config-table = "config"

  # Name of the table to be created/used for storing metadata
  metadata-table = "metadata"

  # replication strategy to use. SimpleStrategy or NetworkTopologyStrategy
  replication-strategy = "SimpleStrategy"

  # Replication factor to use when creating a keyspace. Is only used when replication-strategy is SimpleStrategy.
  replication-factor = 1

  # Replication factor list for data centers, e.g. ["dc1:3", "dc2:2"]. Is only used when replication-strategy is NetworkTopologyStrategy.
  data-center-replication-factors = []

  # Write consistency level
  write-consistency = "ONE"

  # Read consistency level
  read-consistency = "ONE"

  # Maximum number of snapshot metadata to load per recursion (when trying to
  # find a snapshot that matches specified selection criteria). Only increase
  # this value when selection criteria frequently select snapshots that are
  # much older than the most recent snapshot i.e. if there are much more than
  # 10 snapshots between the most recent one and selected one. This setting is
  # only for increasing load efficiency of snapshots.
  max-metadata-result-size = 10

  # Maximum size of result set
  max-result-size = 50001

  # Dispatcher for the plugin actor.
  plugin-dispatcher = "cassandra-snapshot-store.default-dispatcher"

  # Default dispatcher for plugin actor.
  default-dispatcher {
    type = Dispatcher
    executor = "fork-join-executor"
    fork-join-executor {
      parallelism-min = 2
      parallelism-max = 8
    }
  }
}


play.crypto.secret = "momomobil3"

play.i18n {
  langs = [ "en" ]

  # Whether the language cookie should be secure or not
  #langCookieSecure = true

  # Whether the HTTP only attribute of the cookie should be set to true
  #langCookieHttpOnly = true
}

play.http {
  session {
    #secure = true
    httpOnly = true
    #maxAge = 300
    #domain = "example.com"
  }
}

play.ws {
  # Sets HTTP requests not to follow 302 requests
  #followRedirects = false

  # Sets the maximum number of open HTTP connections for the client.
  #ahc.maxConnectionsTotal = 50

  ## WS SSL
  # https://www.playframework.com/documentation/latest/WsSSL
  # ~~~~~
  ssl {
    # Configuring HTTPS with Play WS does not require programming.  You can
    # set up both trustManager and keyManager for mutual authentication, and
    # turn on JSSE debugging in development with a reload.
    #debug.handshake = true
    #trustManager = {
    #  stores = [
    #    { type = "JKS", path = "exampletrust.jks" }
    #  ]
    #}
  }
}

play.filters {
  cors {
    pathPrefixes = ["/"]
    allowedOrigins = null
    allowedHttpMethods = null
    preflightMaxAge = 1 hour
    supportsCredentials = true
  }

  csrf {
    # Sets the cookie to be sent only over HTTPS
    #cookie.secure = true

    # Defaults to CSRFErrorHandler in the root package.
    #errorHandler = MyCSRFErrorHandler
  }

  headers {
    # The X-Frame-Options header. If null, the header is not set.
    #frameOptions = "DENY"

    # The X-XSS-Protection header. If null, the header is not set.
    #xssProtection = "1; mode=block"

    # The X-Content-Type-Options header. If null, the header is not set.
    #contentTypeOptions = "nosniff"

    # The X-Permitted-Cross-Domain-Policies header. If null, the header is not set.
    #permittedCrossDomainPolicies = "master-only"

    # The Content-Security-Policy header. If null, the header is not set.
    #contentSecurityPolicy = "default-src 'self'"
  }
}
